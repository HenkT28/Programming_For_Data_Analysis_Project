# Programming For Data Analysis Project repository

This document contains the instructions for Project 2019 for Programming for Data Analysis.

To access the repository, please go through below instructions:

1). Go to Github web site - User Account: HenkT28

<https://github.com/HenkT28>

2). Then go to Repositories, and select Programming_For_Data_Analysis_Project. Alternatively go to "Clone or download" drop down menu and copy below url:

<https://github.com/HenkT28/Programming_For_Data_Analysis_Project.git>

Then open up cmder (see futher below for download instructions) and run below command to clone the repository locally on your machine:

* git clone <https://github.com/HenkT28/Programming_For_Data_Analysis_Project.git>

STUDENT: Henk Tjalsma

GMIT email address:

G00376321@gmit.ie

## Problem statement

For this project I created a data set by simulating a real-world phenomenon of my choosing. I could pick any phenomenon I wished – you can pick one that is of interest to you in your personal or professional life. Then, rather than collect data related to the phenomenon, you should model and synthesise such data using Python.

It was suggested to use the numpy.random package for this purpose.

Specifically, in this project you should:

1. Choose a real-world phenomenon that can be measured and for which you could collect at least one-hundred data points across at least four different variables.

2. Investigate the types of variables involved, their likely distributions, and their relationships with each other.

3. Synthesise/simulate a data set as closely matching their properties as possible.

4. Detail your research and implement the simulation in a Jupyter notebook – the data set itself can simply be displayed in an output cell within the notebook.

Note that this project is about simulation – you must synthesise a data set. Some students may already have some real-world data sets in their own files. It is okay to base your synthesised data set on these should you wish (please reference it if you do), but the main task in this project is to create a synthesised data set.

## Installing Cmder, VS Code and Ananconda (which includes NumPy, Jupyter)

To answer these four questions, I installed and used a number of different software packages:

* Anaconda Distribution

The open-source Anaconda Distribution is the easiest way to perform Python/R data science and machine learning on Linux, Windows, and Mac OS X. [6]

It is the industry standard for developing, testing, and training on a single machine, enabling individual data scientists to:

    Quickly download 1,500+ Python/R data science packages.
    Manage libraries, dependencies, and environments with Conda.
    Develop and train machine learning and deep learning models with scikit-learn, TensorFlow, and Theano.
    Analyze data with scalability and performance with Dask, NumPy, pandas, and Numba.
    Visualize results with Matplotlib, Seaborn, Bokeh, Datashader, and Holoviews.

Anaconda is free and easy to install, and it offers free community support.

Anaconda3 includes Python 3.7.

<https://www.anaconda.com/distribution/>

<https://docs.anaconda.com/anaconda/>

* Jupyter Notebook

The Jupyter Notebook [5] is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more.

As the Anaconda Distribution includes Jupyter as well, there was no need to download and install it separately.

<https://jupyter.org/install>

* NumPy

To use NumPy on the local machine, I downloaded and installed anaconda package distribution, which installs Python [7] and other important Python libraries including NumPy, Pandas, Seaborn, Matplotlib and SciPy (useful for machine learning).

It contains among other things:

    A powerful N-dimensional array object.

    Sophisticated (broadcasting) functions.

    Tools for integrating C/C++ and Fortran code.

    Useful linear algebra, Fourier transform, and random number capabilities.

* Pandas

Pandas is a common Python tool for data manipulation and analysis, and is included with Anaconda. [9]

* Seaborn

Seaborn is a Python visualization library based on matplotlib. It provides a high-level interface for drawing attractive statistical graphics. Again it comes installed with Anaconda. [11]

* Matplotlib

Matplotlib is a python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. Matplotlib can be used in Python scripts, the Python and IPython shell (ala MATLAB or Mathematica), web application servers, and six graphical user interface toolkits. It comes with anaconda package distribution. [10]

* SciPy

SciPy is a Python-based ecosystem of open-source software for mathematics, science, and engineering. [12]

* Scikit-learn [93]

    Simple and efficient tools for predictive data analysis.

    Accessible to everybody, and reusable in various contexts.

    Built on NumPy, SciPy, and matplotlib.

    Open source, commercially usable - BSD license.

* Cmder

Cmder is a software package which provides a nice command line interface on Windows [8].

I use Cmder (command line interface) for changing the working directory on my local machine, i.e. Programming_For_Data_Analysis_Project, from there I launch Jupyter notebook.

<https://cmder.net/>

* Visual Studio Code

VS Code is a lightweight but powerful source code editor.

It is a new type of tool that combines the simplicity of a code editor with what developers need for their core edit-build-debug cycle. Code provides comprehensive editing and debugging support, an extensibility model, and lightweight integration with existing tools. [13]

I used it to make changes to the readme in my repository.

<https://code.visualstudio.com/>

## HowTo run Jupyter notebook

I'll be using Jupyter Notebook not Jupyter Lab in this assignment (see below the difference between the 2 interfaces):

-> Jupyter Notebook is a web-based interactive computational environment for creating Jupyter notebooks documents. It supports several languages like Python (IPython), Julia, R etc, and is largely used for data analysis, data visualization and further interactive, exploratory computing.

-> Jupyter Lab is a popular 'new' interface for working with Jupyter Notebooks. It is an interactive development environment for working with notebooks, code and data — and hence extremely extensible.

Once I've navigated to the correct working directory on my local machine, through Cmder, i.e. Programming_For_Data_Analysis_Project, I start Jupyter by running "jupyter notebook" command.

The jupyter notebook is called Programming_For_Data_Analysis_Project.ipynb, and contains the body of my work.
